#!/usr/bin/env python3
"""
Week 1 Optimizations Benchmark - FAST version
"""

import random
import shutil
import statistics
import tempfile
import time

import vjson


def benchmark():
    temp_dir = tempfile.mkdtemp()
    print(f"=" * 70)
    print(f"WEEK 1 OPTIMIZATIONS BENCHMARK (Fast)")
    print(f"=" * 70)
    print(f"Testing in: {temp_dir}\n")

    try:
        # Setup: Create database with 10K vectors
        db = vjson.PyVectorDB(temp_dir, dimension=128)

        print("Setup: Inserting 10,000 vectors...")
        n_vectors = 10000
        items = []
        for i in range(n_vectors):
            vec = [random.random() for _ in range(128)]
            meta = {
                "index": i,
                "category": f"cat_{i % 100}",
                "score": random.random() * 100,
            }
            items.append((f"vec_{i}", vec, meta))
        db.insert_batch(items)

        print(f"âœ“ Inserted {n_vectors} vectors\n")

        # ================================================================
        # BENCHMARK 1: Batch Search Optimization
        # ================================================================
        print("=" * 70)
        print("BENCHMARK 1: Batch Query Processing (Shared Reverse Map)")
        print("=" * 70)

        n_queries = 100
        queries = [[random.random() for _ in range(128)] for _ in range(n_queries)]
        k = 10

        # Warmup
        _ = db.batch_search(queries[:10], k=k)

        # Optimized batch search
        start = time.time()
        results = db.batch_search(queries, k=k)
        batch_time = time.time() - start

        batch_throughput = n_queries / batch_time

        print(f"Optimized Batch Search ({n_queries} queries, k={k}):")
        print(f"  Total time: {batch_time * 1000:.2f}ms")
        print(f"  Throughput: {batch_throughput:.0f} queries/sec")
        print(f"  Avg latency: {batch_time / n_queries * 1000:.3f}ms per query\n")

        # Individual searches (old approach)
        start = time.time()
        results_individual = [db.search(q, k=k) for q in queries]
        individual_time = time.time() - start

        individual_throughput = n_queries / individual_time

        print(f"Individual Searches ({n_queries} queries, k={k}):")
        print(f"  Total time: {individual_time * 1000:.2f}ms")
        print(f"  Throughput: {individual_throughput:.0f} queries/sec")
        print(f"  Avg latency: {individual_time / n_queries * 1000:.3f}ms per query\n")

        speedup = individual_time / batch_time
        print(f"ðŸš€ SPEEDUP: {speedup:.2f}x faster!")
        print(
            f"   Batch is {(speedup - 1) * 100:.1f}% faster than individual searches\n"
        )

        # ================================================================
        # BENCHMARK 2: Batch Size Scaling
        # ================================================================
        print("=" * 70)
        print("BENCHMARK 2: Scaling with Batch Size")
        print("=" * 70)

        print(f"{'Batch Size':<12} {'Time (ms)':<14} {'Throughput (q/s)':<18}")
        print("-" * 70)

        for batch_size in [1, 10, 50, 100, 200]:
            test_queries = [
                [random.random() for _ in range(128)] for _ in range(batch_size)
            ]

            start = time.time()
            _ = db.batch_search(test_queries, k=10)
            elapsed = time.time() - start

            qps = batch_size / elapsed
            print(f"{batch_size:<12} {elapsed * 1000:<14.2f} {qps:<18.0f}")

        print()

        # ================================================================
        # BENCHMARK 3: k Value Impact
        # ================================================================
        print("=" * 70)
        print("BENCHMARK 3: Impact of k (result set size)")
        print("=" * 70)

        test_queries_k = [[random.random() for _ in range(128)] for _ in range(50)]

        print(f"{'k':<8} {'Time (ms)':<14} {'Throughput (q/s)':<18}")
        print("-" * 70)

        for k in [5, 10, 20, 32, 50, 100]:
            start = time.time()
            _ = db.batch_search(test_queries_k, k=k)
            elapsed = time.time() - start

            qps = len(test_queries_k) / elapsed
            marker = " â† SmallVec optimized" if k <= 32 else ""
            print(f"{k:<8} {elapsed * 1000:<14.2f} {qps:<18.0f}{marker}")

        print()

        # ================================================================
        # BENCHMARK 4: Memory Savings
        # ================================================================
        print("=" * 70)
        print("BENCHMARK 4: Memory Efficiency")
        print("=" * 70)

        num_vectors = len(db)
        avg_id_length = 10  # "vec_12345"

        # Old: Clone all IDs
        memory_old_mb = (num_vectors * avg_id_length) / 1024 / 1024

        # New: References only
        memory_new_mb = (num_vectors * 8) / 1024 / 1024

        memory_saved_mb = memory_old_mb - memory_new_mb
        reduction_pct = (1 - memory_new_mb / memory_old_mb) * 100

        print(f"Database: {num_vectors:,} vectors")
        print(f"Old (clone all IDs):  {memory_old_mb:.2f} MB per search")
        print(f"New (references):     {memory_new_mb:.2f} MB per search")
        print(
            f"Saved:                {memory_saved_mb:.2f} MB ({reduction_pct:.1f}% reduction)\n"
        )

        # ================================================================
        # SUMMARY
        # ================================================================
        print("=" * 70)
        print("WEEK 1 OPTIMIZATION RESULTS")
        print("=" * 70)

        print("\nâœ… Key Improvements:")
        print(f"  â€¢ Batch search speedup: {speedup:.2f}x")
        print(f"  â€¢ Memory reduction: {reduction_pct:.1f}%")
        print(f"  â€¢ Throughput: {batch_throughput:.0f} queries/sec")
        print()

        print("ðŸ“Š Optimizations Applied:")
        print("  1. Shared reverse map across batch queries")
        print("  2. Reference-based ID lookups (no cloning)")
        print("  3. SmallVec for small result sets (k â‰¤ 32)")
        print()

        print("ðŸŽ¯ Best For:")
        print("  â€¢ Batch query processing")
        print("  â€¢ High-throughput workloads")
        print("  â€¢ Memory-constrained environments")

    finally:
        try:
            shutil.rmtree(temp_dir)
            print(f"\n\nCleaned up: {temp_dir}")
        except:
            print(f"\n\nNote: Manual cleanup may be needed: {temp_dir}")


if __name__ == "__main__":
    benchmark()
